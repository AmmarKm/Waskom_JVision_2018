{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on motion energy model implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the components underlying a spatiotemporal energy model of motion perception. The model was originally introduced in 1985 by EH Adelson and JR Bergen. The basic idea is to think of motion velocity as an orientation in space-time. The model works by constructing filters with joint selectivity for speed and direction (velocity), which are then convolved with a movie of the motion stimulus.\n",
    "\n",
    "The specific Python implemenation here was written by ML Waskom based on an earlier MATLAB implementation by R Kiani. The notebook is intended to provide some intuition for the parameters of the model and to show how the high-level interface can be used for extracting motion energy estimates from a dynamic stimulus.\n",
    "\n",
    "This notebook is best viewed locally, because it has some interactive demos and movies of the stimulus that are not reproduced in the static HTML representation.\n",
    "\n",
    "### References:\n",
    "\n",
    "Adelson EH & Bergen JR (1985). [Spatiotemporal energy models for perception of motion](https://www.ncbi.nlm.nih.gov/pubmed/3973762). *J Opt Soc Am A* 2(2):284-99.\n",
    "\n",
    "Kiani R, Hanks TD, Shadlen MN (2008). [Bounded integration in parietal cortex underlies decisions even when viewing duration is dictated by the environment.\n",
    "](https://www.ncbi.nlm.nih.gov/pubmed/18354005). *J Neurosci* 28(12):3017-29.\n",
    "\n",
    "Waskom ML, Asfour JW, Kiani R (2018). [Perceptual insensitivity to higher-order statistical moments of coherent random dot motion](https://www.biorxiv.org/content/early/2018/04/26/261370). *J Vision*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.fft import fftn, fftshift, fftfreq\n",
    "from scipy.ndimage import rotate\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import motionenergy as me\n",
    "import stimulus as stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set(font_scale=1.3, color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components of the spatiotemporal energy model\n",
    "\n",
    "The spatiotemporal filters are constructed from space-time seperable components. There are two functions each for the spatial and temporal components. Using pairs of quadrature filters will make the model invariant to phase. The full spatial filters are defined as follows, letting $\\alpha = \\tan^{-1}(x/\\sigma_c)$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f_1(x,y) &= \\cos^4(\\alpha)\\cos(4\\alpha)\\exp\\big(-\\frac{y^2}{2\\sigma_g^2}\\big) \\\\\n",
    "f_2(x,y) &= \\cos^4(\\alpha)\\sin(4\\alpha)\\exp\\big(-\\frac{y^2}{2\\sigma_g^2}\\big),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "On one spatial axis, the filters are fourth-order Cauchy functions (similar to a Gabor pattern) controlled by a parameter $\\sigma_c$. The demo below shows how this parameter determines the width of the filter; together with the temporal components (see below), it is part of what gives the filter speed selectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def cauchy_param_tutorial(σ_c=(.1, .6, .05)):\n",
    "    \"\"\"Interactive widget to demo spatial component of filters.\"\"\"\n",
    "    x = me.filter_grid(256, .005, center=True)\n",
    "    f1, f2 = me.cauchy(x, σ_c)\n",
    "    f, ax = plt.subplots()\n",
    "    ax.plot(x, f1, x, f2)\n",
    "    ax.set(xlim=(-.65, .65),\n",
    "           xlabel=\"Selective axis (deg)\",\n",
    "           ylabel=\"Amplitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the orthogonal axis, the filters are windowed with a Gaussian envelope; the two-dimensional filter is then oriented in space. The orientation of the filter determines its direction selectivity. The width of the Gaussian envelope influences how narrowly or broadly it is tuned around its preferred direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centered_colormap(data):\n",
    "    \"\"\"Set vmin and vmax to put center of colormap at 0.\"\"\"\n",
    "    lim = np.abs([data.min(), data.max()]).max()\n",
    "    return dict(vmin=-lim, vmax=+lim, cmap=\"icefire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def spatial_param_tutorial(σ_c=(.05, .65), σ_g=(.02, .2, .02), θ=(-90, 90, 10)):\n",
    "    \"\"\"Interactive widget to demo full spatial component of filters.\"\"\"\n",
    "    x = me.filter_grid(125, .02, True)\n",
    "    xx, yy = np.meshgrid(x, x)\n",
    "\n",
    "    c1, c2 = me.cauchy(x, σ_c, 4)\n",
    "    g = me.gaussian_envelope(x, σ_g)\n",
    "\n",
    "    qx1, qy = np.meshgrid(c1, g)\n",
    "    qx2, qy = np.meshgrid(c2, g)\n",
    "    filters = (\"Even filter ($f_1$)\", qx1), (\"Odd filter ($f_2$)\", qx2)\n",
    "    \n",
    "    f, axes = plt.subplots(1, 2, figsize=(6, 3), sharey=True)\n",
    "    for ax, (title, filt) in zip(axes, filters):\n",
    "\n",
    "        filt = rotate(filt * qy, θ, reshape=False)\n",
    "        ax.pcolormesh(xx, yy, filt, **centered_colormap(filt))\n",
    "        ax.set(title=title)\n",
    "\n",
    "    f.subplots_adjust(0, 0, 1, 1, .02)\n",
    "    axes[0].set(xlabel=\"Selective axis (deg)\",\n",
    "                ylabel=\"Non-selective axis (deg)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temporal filters model the impulse response of direction-selective neurons in cortex. They are implemented as a pair of difference-of-poisson functions:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "g_1(t) &= (kt)^3\\exp(-kt)\\Bigg[\\frac{1}{3!} - \\frac{(kt)^2}{(3 + 2)!}\\Bigg] \\\\\n",
    "g_2(t) &= (kt)^5\\exp(-kt)\\Bigg[\\frac{1}{5!} - \\frac{(kt)^2}{(5 + 2)!}\\Bigg]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The main parameter is $k$, which controls the latency of the filter. Together with $\\sigma_c$, this will determine the speed selectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def temporal_param_tutorial(k=(30, 70, 5)):\n",
    "    \"\"\"Interactive widget to demo temporal component of filters.\"\"\"\n",
    "    t = me.filter_grid(128, .005)\n",
    "    f1 = me.temporal_impulse_response(t, 3, k)\n",
    "    f2 = me.temporal_impulse_response(t, 5, k)\n",
    "    f, ax = plt.subplots()\n",
    "    lines = ax.plot(t, f1, t, f2)\n",
    "    ax.legend(lines, [\"$g_1$\", \"$g_2$\"])\n",
    "    ax.set(xlabel=\"Time (sec)\", ylabel=\"Amplitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting the components together\n",
    "\n",
    "These spatial and temporal functions are combined to create full three-dimensional spatiotemporal filters. When the model is used, each stimulus is convolved with four different filters. There are two filters oriented to be selective for motion in a given direction (preferred) and then two filters oriented to be selective for motion in the reverse direction (null). This is done because motion energy is defined as the difference between the energy in the preferred and null directions (i.e. opponent motion energy). For each direction, there is an even filter and an odd filter. The responses of this quadrature pair are combined so that the system is invariant to phase.\n",
    "\n",
    "When plotting the filters on a two-dimensional axes (selective spatial dimension and temporal dimension), they look like schmeared Gabors. This emphasizes how the model characterizes motion as an orientation in space-time. Just as an oriented Gabor filter is selective for a spatial orientation, an oriented Gabor schmear is selective for a velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the size and resolution of the filters\n",
    "nx, dx = 235, .01\n",
    "nt, dt = 300, .001\n",
    "size = nx, 1, nt\n",
    "res = dx, dx, dt\n",
    "\n",
    "# Define the mesh that the filters are sampled on\n",
    "x = me.filter_grid(nx, dx, center=True)\n",
    "t = me.filter_grid(nt, dt)\n",
    "xx, tt = np.meshgrid(x, t, indexing=\"ij\")\n",
    "\n",
    "# Create a set of motion energy filters\n",
    "filters = me.motion_filters(size, res)\n",
    "\n",
    "# Show each filter in the set\n",
    "f, axes = plt.subplots(1, 4, sharey=True, figsize=(10, 4))\n",
    "titles = [\"Even preferred\", \"Odd preferred\", \"Even null\", \"Odd null\"]\n",
    "\n",
    "for ax, title, filt in zip(axes, titles, filters):\n",
    "    filt = filt.squeeze()[:, -nt:]\n",
    "    ax.pcolormesh(xx, tt, filt, **centered_colormap(filt))\n",
    "    ax.set_title(title)\n",
    "\n",
    "axes[0].set(xlabel=\"Selective axis (deg)\", ylabel=\"Time (sec)\")\n",
    "f.subplots_adjust(0, 0, 1, 1, .02, .02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show the spectral representation of the filter to get a better sense for how the spatial and temporal parameters control the speed selectivity. What we want is to find a ratio between the spatial and temporal frequencies so that the filter has maximum power at the speed of the stimulus we want to characterize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def spatiotemporal_tutorial(filter=titles, k=(30, 80, 5), σ_c=(.05, .65, .05)):\n",
    "    \"\"\"Interactive widget to demo spatiotemporal selectivity.\"\"\"\n",
    "    # Determine the size and resolution of the filters\n",
    "    nx, nt = 41, 41\n",
    "    dx, dt = .0436, .0133\n",
    "    size = nx, 1, nt\n",
    "    res = dx, .01, dt\n",
    "\n",
    "    # Create the filter set and select the one we want to view\n",
    "    filters = me.motion_filters(size, res, k=k, csigx=σ_c)\n",
    "    filt = filters[titles.index(filter)]\n",
    "\n",
    "    # Take the fourier transform of the filter to show its spectral representation\n",
    "    filt_fft = np.abs(fftshift(fftn(filt)).squeeze()).real\n",
    "\n",
    "    # The filter is causal in time, so crop off the first half\n",
    "    filt = filt.squeeze()[:, nt:]\n",
    "\n",
    "    # Define the spatial mesh\n",
    "    xs = me.filter_grid(nx, dx, center=True)\n",
    "    ts = me.filter_grid(nt, dt)\n",
    "    xx, tt = np.meshgrid(xs, ts, indexing=\"ij\")\n",
    "\n",
    "    # Define the spectral mesh\n",
    "    fxs = fftshift(fftfreq(nx, dx))\n",
    "    fts = fftshift(fftfreq(nt * 2 - 1, dt))\n",
    "    fxx, ftt = np.meshgrid(fxs, fts, indexing=\"ij\")\n",
    "\n",
    "    # Plot the spatial and spectral representations of the filter\n",
    "    gridspec = {\"width_ratios\": (4, 5)}\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 5), gridspec_kw=gridspec)\n",
    "\n",
    "    ax1.pcolormesh(xx, tt, filt, **centered_colormap(filt))\n",
    "    ax2.pcolormesh(fxx, ftt, filt_fft)\n",
    "\n",
    "    ax1.set(xlabel=\"Selective axis ($\\circ$)\", ylabel=\"Time (s)\")\n",
    "    ax2.set(xlabel=\"$\\omega_x$ (cycle / sec)\", ylabel=\"$\\omega_t$ (cycle / deg)\")\n",
    "    f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the filters to model motion perception\n",
    "\n",
    "Having gone through the components of the model, the next section demonstrates how it might actually be used with a perceptual stimulus.\n",
    "\n",
    "First, we are going to generate a random dot motion stimulus as a 3D movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the parameters of the display\n",
    "\n",
    "radius = 3  # radius of the stimulus in degrees\n",
    "ppd = 40  # display spatial resolution (pixels per degree)\n",
    "framerate = 1 / 60  # display temporal resolution\n",
    "\n",
    "# Determine the parameters of the stimulus\n",
    "\n",
    "density = 100.2  # density of dots in dots per deg^2 per sec\n",
    "size = 3  # size of each dot in pixels \n",
    "speed = 5  # speed of coherent motion in deg per sec\n",
    "coherence = .9  # proportion of dots displaced coherently\n",
    "moments = 0, 20, 0, 3  # mean, sd, skew, and variance of dot motion\n",
    "duration = 1  # length of the movit, in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = stim.dot_movie(radius, density, size, speed, coherence, ppd, framerate, duration, moments)\n",
    "stim.play_movie(dots, framerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract the motion energy of this stimulus, we convolve the three dimensional arrays (the stimulus movie and each motion energy filter). The filters should have the same resolution as the movie, but they can have a different size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_shape = 64, 64, 25 \n",
    "filter_res = 1 / ppd, 1 / ppd, framerate\n",
    "filters = me.motion_filters(filter_shape, filter_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the filters to the stimulus will return a three dimensional array with the same shape as the stimulus movie. We can visualize it in the same way and see that the model has replaced each dot with a local burst of motion energy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots_energy = me.apply_motion_energy_filters(dots, filters)\n",
    "stim.play_movie(dots_energy, framerate, vmax=10, cmap=\"mako\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The motion energy can be summed across space and shown as a function of time. Shown this way, it is clear that there is an initial rise from zero to a steady state; this rise time is determined by the temporal latency parameter. Becauase the random dot stimulus is stochastic, the motion energy then fluctuates somewhat around its steady state value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "t = me.filter_grid(duration / framerate, framerate)\n",
    "ax.plot(t, dots_energy.sum(axis=(0, 1)))\n",
    "ax.set(xlim=(0, duration), ylim=(0, None),\n",
    "       xlabel=\"Time (sec)\",\n",
    "       ylabel=\"Motion energy (a.u.)\")\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a bank of filters with different preferred orientations to model the response of a population of direction-selective cells to a particular stimulus. Alternatively, you can think of this as estimating the tuning curve of the filter system given the set of parameters. Constructing the motion energy profile involves a lot of convolution, so the next cell will take some time to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = [-60, -45,  -30, -15, 0, +15, +30, +45, +60]\n",
    "filter_bank = me.filter_bank(thetas, filter_shape, filter_res)\n",
    "bank_energy = np.sum(me.apply_motion_energy_filters(dots, filter_bank), axis=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the motion energy profile, we take the mean over time (after cropping to avoid the initial latency period) for each direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = me.filter_grid(duration / framerate, framerate)\n",
    "energy_profile = bank_energy[:, t > .2].mean(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot(thetas, energy_profile, \"o-\")\n",
    "ax.set(xlabel=r\"Motion energy filter orientation ($\\theta$)\",\n",
    "       ylabel=\"Motion energy (a.u.)\")\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
